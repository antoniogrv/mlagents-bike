{
    "name": "root",
    "gauges": {
        "MoveToGoal.Policy.Entropy.mean": {
            "value": 0.9210991859436035,
            "min": 0.8509588837623596,
            "max": 2.191768169403076,
            "count": 80
        },
        "MoveToGoal.Policy.Entropy.sum": {
            "value": 46165.4921875,
            "min": 42496.88671875,
            "max": 110903.46875,
            "count": 80
        },
        "MoveToGoal.Step.mean": {
            "value": 3999976.0,
            "min": 49964.0,
            "max": 3999976.0,
            "count": 80
        },
        "MoveToGoal.Step.sum": {
            "value": 3999976.0,
            "min": 49964.0,
            "max": 3999976.0,
            "count": 80
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.mean": {
            "value": 22.283042907714844,
            "min": -82.7142105102539,
            "max": 36.281734466552734,
            "count": 80
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.sum": {
            "value": 17759.5859375,
            "min": -65592.3671875,
            "max": 28880.26171875,
            "count": 80
        },
        "MoveToGoal.Environment.EpisodeLength.mean": {
            "value": 1642.40625,
            "min": 389.4583333333333,
            "max": 3346.75,
            "count": 80
        },
        "MoveToGoal.Environment.EpisodeLength.sum": {
            "value": 52557.0,
            "min": 37388.0,
            "max": 65966.0,
            "count": 80
        },
        "MoveToGoal.Environment.CumulativeReward.mean": {
            "value": 591.5625,
            "min": -2025.5555555555557,
            "max": 882.1111111111111,
            "count": 80
        },
        "MoveToGoal.Environment.CumulativeReward.sum": {
            "value": 18930.0,
            "min": -126752.0,
            "max": 23817.0,
            "count": 80
        },
        "MoveToGoal.Policy.ExtrinsicReward.mean": {
            "value": 591.5625,
            "min": -2025.5555555555557,
            "max": 882.1111111111111,
            "count": 80
        },
        "MoveToGoal.Policy.ExtrinsicReward.sum": {
            "value": 18930.0,
            "min": -126752.0,
            "max": 23817.0,
            "count": 80
        },
        "MoveToGoal.Losses.PolicyLoss.mean": {
            "value": 0.02392589934946348,
            "min": 0.021079930141568184,
            "max": 0.026398713490925728,
            "count": 80
        },
        "MoveToGoal.Losses.PolicyLoss.sum": {
            "value": 0.1196294967473174,
            "min": 0.0854584646721681,
            "max": 0.13199356745462865,
            "count": 80
        },
        "MoveToGoal.Losses.ValueLoss.mean": {
            "value": 3714.8462548828124,
            "min": 1125.703252665202,
            "max": 19261.576391601564,
            "count": 80
        },
        "MoveToGoal.Losses.ValueLoss.sum": {
            "value": 18574.23127441406,
            "min": 5628.51626332601,
            "max": 77046.30556640626,
            "count": 80
        },
        "MoveToGoal.Policy.LearningRate.mean": {
            "value": 1.6669894443699939e-06,
            "min": 1.6669894443699939e-06,
            "max": 0.00029806963189345627,
            "count": 80
        },
        "MoveToGoal.Policy.LearningRate.sum": {
            "value": 8.33494722184997e-06,
            "min": 8.33494722184997e-06,
            "max": 0.00147299025900325,
            "count": 80
        },
        "MoveToGoal.Policy.Epsilon.mean": {
            "value": 0.10055563000000001,
            "min": 0.10055563000000001,
            "max": 0.19935654375,
            "count": 80
        },
        "MoveToGoal.Policy.Epsilon.sum": {
            "value": 0.50277815,
            "min": 0.43253680000000005,
            "max": 0.9909967500000003,
            "count": 80
        },
        "MoveToGoal.Policy.Beta.mean": {
            "value": 3.772593699999991e-05,
            "min": 3.772593699999991e-05,
            "max": 0.004967891533125,
            "count": 80
        },
        "MoveToGoal.Policy.Beta.sum": {
            "value": 0.00018862968499999957,
            "min": 0.00018862968499999957,
            "max": 0.024550737824999995,
            "count": 80
        },
        "MoveToGoal.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 80
        },
        "MoveToGoal.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 80
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1702200783",
        "python_version": "3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Dario\\anaconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/configuration_4mln.yaml --run-id=TrainPeoplePuddleRandomHoles10Dicembre2",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1702204962"
    },
    "total": 4178.5519254,
    "count": 1,
    "self": 0.04111099999954604,
    "children": {
        "run_training.setup": {
            "total": 0.11429430000000007,
            "count": 1,
            "self": 0.11429430000000007
        },
        "TrainerController.start_learning": {
            "total": 4178.3965201,
            "count": 1,
            "self": 4.894714999977623,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.7328978,
                    "count": 1,
                    "self": 10.7328978
                },
                "TrainerController.advance": {
                    "total": 4162.707071300022,
                    "count": 200032,
                    "self": 4.37060349987496,
                    "children": {
                        "env_step": {
                            "total": 2768.3034032000787,
                            "count": 200032,
                            "self": 1827.0271532000925,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 938.4444777999927,
                                    "count": 200032,
                                    "self": 13.213456699994822,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 925.2310210999979,
                                            "count": 200032,
                                            "self": 925.2310210999979
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.831772199993697,
                                    "count": 200032,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 4164.516222400079,
                                            "count": 200032,
                                            "is_parallel": true,
                                            "self": 2643.134619600077,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.003557699999999997,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0013484999999997527,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0022092000000002443,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0022092000000002443
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1521.3780451000016,
                                                    "count": 200032,
                                                    "is_parallel": true,
                                                    "self": 43.71899869996082,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 57.88068149993801,
                                                            "count": 200032,
                                                            "is_parallel": true,
                                                            "self": 57.88068149993801
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1294.5364384001111,
                                                            "count": 200032,
                                                            "is_parallel": true,
                                                            "self": 1294.5364384001111
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 125.24192649999172,
                                                            "count": 200032,
                                                            "is_parallel": true,
                                                            "self": 39.911786900238056,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 85.33013959975366,
                                                                    "count": 800128,
                                                                    "is_parallel": true,
                                                                    "self": 85.33013959975366
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1390.033064600068,
                            "count": 200032,
                            "self": 9.848565900108724,
                            "children": {
                                "process_trajectory": {
                                    "total": 449.5061332999566,
                                    "count": 200032,
                                    "self": 448.86907169995567,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.6370616000009477,
                                            "count": 8,
                                            "self": 0.6370616000009477
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 930.6783654000026,
                                    "count": 389,
                                    "self": 632.9709844000065,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 297.70738099999613,
                                            "count": 11670,
                                            "self": 297.70738099999613
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.000006346264854e-07,
                    "count": 1,
                    "self": 8.000006346264854e-07
                },
                "TrainerController._save_models": {
                    "total": 0.06183520000013232,
                    "count": 1,
                    "self": 0.001512699999693723,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.060322500000438595,
                            "count": 1,
                            "self": 0.060322500000438595
                        }
                    }
                }
            }
        }
    }
}